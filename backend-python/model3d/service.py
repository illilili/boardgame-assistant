# -*- coding: utf-8 -*-
"""
ê²Œì„ êµ¬ì„±ìš”ì†Œ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥ë°›ì•„ 3D ëª¨ë¸ì„ ìƒì„±í•˜ëŠ” ì „ì²´ ë¡œì§ì„ ë‹´ë‹¹í•˜ëŠ” ëª¨ë“ˆ.
- OpenAI: ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ 3D ëª¨ë¸ë§ì— ì í•©í•œ ì‹œê°ì  í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
- MeshyClient: Meshy AI APIì™€ í†µì‹ í•˜ì—¬ 3D ëª¨ë¸ì˜ ì´ˆì•ˆ ìƒì„± ë° ì •êµí™”ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
"""

# service.py

import os
import requests
import time
import logging
from dotenv import load_dotenv
from typing import Optional, Dict, Any
from openai import OpenAI

# --- 1. ë¡œê¹… ë° ì „ì—­ í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
load_dotenv()
openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# --- 2. OpenAI í”„ë¡¬í”„íŠ¸ ìƒì„± ê¸°ëŠ¥ ---
def create_visual_prompt(item_name: str, item_description: str, art_style: str) -> Optional[str]:
    """OpenAIë¥¼ ì‚¬ìš©í•´ 3D ëª¨ë¸ë§ì„ ìœ„í•œ ì‹œê°ì  ë¬˜ì‚¬ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    logging.info(f"[OpenAI] '{item_name}'ì˜ ì‹œê°ì  í”„ë¡¬í”„íŠ¸ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    try:
        system_prompt = (
           "You are a creative prompt engineer for a text-to-3D AI. "
           "Your task is to create a concise but detailed visual description in English for a **board game piece miniature**, "
           "based on a game item's name, its role, and desired art style. "
           "The model should be suitable as a **physical, tabletop game component,** focusing on a **clear silhouette** and recognizable features. "
           "Describe materials, shape, and key features. "
           "IMPORTANT: The entire description must be under 500 characters."
        )
        user_prompt = (
            f"Game Item Name: {item_name}\n"
            f"Item's Role/Description: {item_description}\n"
            f"Art Style: {art_style}"
        )
        response = openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]
        )
        visual_prompt = response.choices[0].message.content
        logging.info(f"[OpenAI] ìƒì„±ëœ í”„ë¡¬í”„íŠ¸: {visual_prompt}")
        return visual_prompt
    except Exception as e:
        logging.error(f"[OpenAI] í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return None
# --- 3. Meshy AI í´ë¼ì´ì–¸íŠ¸ í´ë˜ìŠ¤  ---
class MeshyClient:
    """Meshy AI APIì™€ì˜ í†µì‹ ì„ ë‹´ë‹¹í•˜ëŠ” ìµœì í™”ëœ í´ë¼ì´ì–¸íŠ¸ í´ë˜ìŠ¤."""
    def __init__(self, api_key: Optional[str]):
        if not api_key:
            raise ValueError("Meshy API í‚¤ê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        self.base_url = "https://api.meshy.ai/openapi/v2/text-to-3d"
        self.headers = {"Authorization": f"Bearer {api_key}"}

    def _poll_task_status(self, task_id: str, task_name: str) -> Optional[Dict[str, Any]]:
        """Helper ë©”ì„œë“œ: ì‘ì—… ìƒíƒœë¥¼ í™•ì¸í•˜ê³ , ì™„ë£Œë˜ë©´ ê²°ê³¼ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        logging.info(f"[{task_name}] ì‘ì—…({task_id})ì˜ ì™„ë£Œë¥¼ ê¸°ë‹¤ë¦½ë‹ˆë‹¤...")
        while True:
            try:
                response = requests.get(f"{self.base_url}/{task_id}", headers=self.headers)
                response.raise_for_status()
                data = response.json()
                status = data.get("status")
                
                if status == "SUCCEEDED":
                    logging.info(f"âœ… [{task_name}] ì‘ì—…({task_id}) ì„±ê³µ!")
                    return data
                elif status == "FAILED":
                    error_msg = data.get("task_error", {}).get("message", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
                    logging.error(f"âŒ [{task_name}] ì‘ì—…({task_id}) ì‹¤íŒ¨. ì›ì¸: {error_msg}")
                    return None
                
                time.sleep(10)
            except requests.exceptions.RequestException as e:
                logging.error(f"âŒ [{task_name}] ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                return None


    # ğŸ‘‡ generate_model í•¨ìˆ˜ë¥¼ ë‹¤ì‹œ ì¶”ê°€í•©ë‹ˆë‹¤.
    def generate_model(self, prompt: str, art_style: str = "realistic") -> Optional[Dict[str, Any]]:
        """[í†µí•© ê¸°ëŠ¥] Previewì™€ Refineì„ ëª¨ë‘ ì‹¤í–‰í•˜ê³  ìµœì¢… ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        # 1ë‹¨ê³„: Preview Task ìƒì„±
        logging.info(f"[Meshy] Preview Task ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        preview_payload = {"mode": "preview", "prompt": prompt, "art_style": art_style}
        try:
            response = requests.post(self.base_url, headers=self.headers, json=preview_payload)
            response.raise_for_status()
            preview_id = response.json().get("result")
        except requests.exceptions.RequestException as e:
            logging.error(f"[Meshy] Preview Task ìƒì„± ìš”ì²­ ì‹¤íŒ¨: {e}")
            return None
        
        preview_result = self._poll_task_status(preview_id, "Preview")
        if not preview_result: return None

        # 2ë‹¨ê³„: Refine Task ìƒì„±
        logging.info(f"[Meshy] Refine Task ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        refine_payload = {"mode": "refine", "preview_task_id": preview_id}
        try:
            response = requests.post(self.base_url, headers=self.headers, json=refine_payload)
            response.raise_for_status()
            refine_id = response.json().get("result")
        except requests.exceptions.RequestException as e:
            logging.error(f"[Meshy] Refine Task ìƒì„± ìš”ì²­ ì‹¤íŒ¨: {e}")
            return None

        refine_result = self._poll_task_status(refine_id, "Refine")
        if not refine_result: return None

        # 3ë‹¨ê³„: ìµœì¢… ê²°ê³¼ ë°˜í™˜
        return {
            "preview_id": preview_id,
            "refine_id": refine_id,
            "preview_url": preview_result.get("model_urls", {}).get("glb"),
            "refined_url": refine_result.get("model_urls", {}).get("glb")
        }

# --- 4. ë©”ì¸ í…ŒìŠ¤íŠ¸ ë¡œì§ ---
if __name__ == '__main__':
    meshy_client = MeshyClient(api_key=os.getenv("MESHY_API_KEY"))
    test_component = {"name": "ë¶ˆì˜ ê²€", "description": "ì ì—ê²Œ ë¶ˆíƒ€ëŠ” í”¼í•´ 2ë¥¼ ê°€í•œë‹¤.", "style": "realistic"}
    
    visual_prompt = create_visual_prompt(
        item_name=test_component["name"],
        item_description=test_component["description"],
        art_style=test_component["style"]
    )

    if visual_prompt:
        # ì´ ë¶€ë¶„ì—ì„œ generate_modelì„ ì •ìƒì ìœ¼ë¡œ í˜¸ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        final_result = meshy_client.generate_model(prompt=visual_prompt, art_style=test_component["style"])
        
        if final_result:
            logging.info("--- âœ… ìµœì¢… ì‘ì—… ì„±ê³µ ---")
            logging.info(f"  - ì´ˆì•ˆ ëª¨ë¸ ë§í¬: {final_result.get('preview_url')}")
            logging.info(f"  - ìµœì¢… ëª¨ë¸ ë§í¬: {final_result.get('refined_url')}")
        else:
            logging.error("--- âŒ ìµœì¢… ì‘ì—… ì‹¤íŒ¨ ---")